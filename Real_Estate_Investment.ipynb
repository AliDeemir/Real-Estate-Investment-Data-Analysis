{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62e0c1cf-f55b-4e39-88f9-70e3337fe43c",
   "metadata": {},
   "source": [
    "# Real Estate Investment Data Analysis for Izmir/Turkey\n",
    "In this personal project python is used for web scraping, data wrangling, data cleaning, and basic analysis\n",
    "## Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0bd306d-29f8-4d48-a6af-ba1f3204e71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in ./venv/lib/python3.9/site-packages (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./venv/lib/python3.9/site-packages (from beautifulsoup4) (2.3.1)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.9/site-packages (2.27.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./venv/lib/python3.9/site-packages (from requests) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.9/site-packages (from requests) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.9/site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in ./venv/lib/python3.9/site-packages (from requests) (2.0.12)\n",
      "Collecting os_sys\n",
      "  Using cached os_sys-2.1.4-py3-none-any.whl (15.6 MB)\n",
      "Collecting pypiwin32\n",
      "  Using cached pypiwin32-223-py3-none-any.whl (1.7 kB)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.9/site-packages (from os_sys) (1.22.2)\n",
      "Collecting geocoder\n",
      "  Using cached geocoder-1.38.1-py2.py3-none-any.whl (98 kB)\n",
      "Collecting cefpython3\n",
      "  Using cached cefpython3-66.0-py2.py3-none-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (67.8 MB)\n",
      "Collecting mysql-connector\n",
      "  Using cached mysql-connector-2.2.9.tar.gz (11.9 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tornado in ./venv/lib/python3.9/site-packages (from os_sys) (6.1)\n",
      "Collecting PyInstaller\n",
      "  Downloading pyinstaller-4.10-py3-none-macosx_10_13_universal2.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hCollecting python-dateutil<2.8,>=2.7\n",
      "  Using cached python_dateutil-2.7.5-py2.py3-none-any.whl (225 kB)\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.9/site-packages (from os_sys) (1.4.1)\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.9/site-packages (from os_sys) (4.62.3)\n",
      "Collecting selenium\n",
      "  Using cached selenium-4.1.2-py3-none-any.whl (963 kB)\n",
      "Collecting psutil\n",
      "  Using cached psutil-5.9.0-cp39-cp39-macosx_10_9_x86_64.whl (238 kB)\n",
      "Collecting os-sys-php\n",
      "  Using cached os_sys_php-2019.10.13-py3-none-any.whl (38.6 MB)\n",
      "Collecting nltk<4.0,>=3.2\n",
      "  Using cached nltk-3.7-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: six in ./venv/lib/python3.9/site-packages (from os_sys) (1.16.0)\n",
      "Collecting Django\n",
      "  Using cached Django-4.0.3-py3-none-any.whl (8.0 MB)\n",
      "Collecting pynput\n",
      "  Using cached pynput-1.7.6-py2.py3-none-any.whl (89 kB)\n",
      "Collecting os_sys\n",
      "  Using cached os_sys-2.1.3-py3-none-any.whl (15.5 MB)\n",
      "  Using cached os_sys-2.1.2-py3-none-any.whl (15.4 MB)\n",
      "  Using cached os_sys-2.1.1-py3-none-any.whl (15.4 MB)\n",
      "  Using cached os_sys-2.1.0-py3-none-any.whl (15.9 MB)\n",
      "  Using cached os_sys-2.0.9-py3-none-any.whl (15.4 MB)\n",
      "  Using cached os_sys-2.0.8-py3-none-any.whl (15.4 MB)\n",
      "  Using cached os_sys-2.0.7-py3-none-any.whl (14.2 MB)\n",
      "  Using cached os_sys-2.0.6-py3-none-any.whl (14.2 MB)\n",
      "  Using cached os_sys-2.0.5-py3-none-any.whl (12.2 MB)\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.2.3-cp39-cp39-macosx_10_9_x86_64.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hCollecting os_sys\n",
      "  Using cached os_sys-2.0.4-py3-none-any.whl (50.9 MB)\n",
      "  Using cached os_sys-2.0.3-py3-none-any.whl (51.8 MB)\n",
      "  Using cached os_sys-2.0.2-py3-none-any.whl (54.1 MB)\n",
      "  Using cached os_sys-2.0.1-py3-none-any.whl (54.1 MB)\n",
      "  Using cached os_sys-2.0.0-py3-none-any.whl (54.1 MB)\n",
      "  Using cached os_sys-1.9.9-py3-none-any.whl (54.1 MB)\n",
      "  Using cached os_sys-1.9.8-py3-none-any.whl (54.1 MB)\n",
      "  Using cached os_sys-1.9.7-py3-none-any.whl (54.1 MB)\n",
      "  Using cached os_sys-1.9.6-py3-none-any.whl (54.1 MB)\n",
      "  Using cached os_sys-1.9.5-py3-none-any.whl (54.1 MB)\n",
      "  Using cached os_sys-1.9.4-py3-none-any.whl (54.1 MB)\n",
      "  Using cached os_sys-1.9.3-py3-none-any.whl (60.4 MB)\n",
      "\u001b[31mERROR: os-sys has an invalid wheel, os-sys has an invalid wheel, could not read 'os_sys-1.9.3.dist-info/WHEEL' file: KeyError(\"There is no item named 'os_sys-1.9.3.dist-info/WHEEL' in the archive\")\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: pandas in ./venv/lib/python3.9/site-packages (1.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./venv/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.9/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in ./venv/lib/python3.9/site-packages (from pandas) (1.22.2)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.9/site-packages (1.22.2)\n",
      "ERROR: unknown command \"pip\"\n",
      "Requirement already satisfied: SQLAlchemy in ./venv/lib/python3.9/site-packages (1.4.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./venv/lib/python3.9/site-packages (from SQLAlchemy) (1.1.2)\n",
      "Requirement already satisfied: xlsxwriter in ./venv/lib/python3.9/site-packages (3.0.2)\n",
      "Requirement already satisfied: matplotlib in ./venv/lib/python3.9/site-packages (3.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.9/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in ./venv/lib/python3.9/site-packages (from matplotlib) (3.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.9/site-packages (from matplotlib) (1.22.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./venv/lib/python3.9/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./venv/lib/python3.9/site-packages (from matplotlib) (9.0.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.9/site-packages (from matplotlib) (4.29.1)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: seaborn in ./venv/lib/python3.9/site-packages (0.11.2)\n",
      "Requirement already satisfied: numpy>=1.15 in ./venv/lib/python3.9/site-packages (from seaborn) (1.22.2)\n",
      "Requirement already satisfied: pandas>=0.23 in ./venv/lib/python3.9/site-packages (from seaborn) (1.4.1)\n",
      "Requirement already satisfied: scipy>=1.0 in ./venv/lib/python3.9/site-packages (from seaborn) (1.8.0)\n",
      "Requirement already satisfied: matplotlib>=2.2 in ./venv/lib/python3.9/site-packages (from seaborn) (3.5.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in ./venv/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (3.0.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (4.29.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./venv/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./venv/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (9.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (21.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.9/site-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "Requirement already satisfied: sorting in ./venv/lib/python3.9/site-packages (1.0.3)\n"
     ]
    }
   ],
   "source": [
    "# Installing Necessary Packages\n",
    "!pip install beautifulsoup4\n",
    "!pip install requests\n",
    "!pip install os_sys   \n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip pip install google-cloud-bigquery\n",
    "!pip install SQLAlchemy\n",
    "!pip install xlsxwriter\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5bc17c-3683-4fd5-a98f-c48a36d5defd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the packages\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import xlsxwriter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sorting\n",
    "from google.cloud import bigquery\n",
    "from google.cloud.exceptions import NotFound\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1308bf-383d-463c-a355-a0c3d78ae166",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Google Bigquery Access Credentials\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"/Users/alidemir/PycharmProjects/SahibindenScraping/local-incline-341518-9c228098b101.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3737e93f-6296-4833-8ebe-65a117e36e5b",
   "metadata": {},
   "source": [
    "## Web Scraping Note:\n",
    "This all scraping script must be in the same code area because of not overwriting the same rows when using the script again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ccaa8b-c8e2-4b58-b4b7-19e7e64f3bc4",
   "metadata": {},
   "source": [
    "### Rent Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b39c78-7472-4121-ad20-8c426e2a1102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating CSV file for rent ads and defining titles\n",
    "with open(\"rent.csv\", \"w\", encoding=\"utf8\", newline=\"\") as f:\n",
    "    thewriter= csv.writer(f)\n",
    "    header = [\"Title\", \"Location\", \"Price\", \"MeterSquare\", \"Number of Rooms\", \"Age\", \"Ad Date\", \"Condition\"]\n",
    "    thewriter.writerow(header)\n",
    "    \n",
    "# User agent for requests\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.3 Safari/605.1.15\"}\n",
    "\n",
    "#Defining web scraping function\n",
    "def getRent(page):\n",
    "    url = f\"https://www.hepsiemlak.com/izmir-kiralik/daire?p37=120406&page={page}\"\n",
    "    page = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    lists = soup.find_all(\"div\", class_=\"listing-item\")\n",
    "\n",
    "\n",
    "\n",
    "    with open(\"rent.csv\", \"a\", encoding=\"utf8\", newline=\"\") as f:\n",
    "\n",
    "        thewriter= csv.writer(f)\n",
    "\n",
    "\n",
    "        for list in lists:\n",
    "            title = list.find(\"div\", class_=\"list-view-header\").text.replace(\"\\n\",\"\")\n",
    "            location = list.find(\"div\", class_=\"list-view-location\").text.replace(\"\\n\",\"\")\n",
    "            price = list.find(\"div\", class_=\"list-view-price\").text.replace(\"\\n\",\"\")\n",
    "            metersquare = list.find(\"span\", class_=\"celly squareMeter list-view-size\").text.replace(\"\\n\",\"\")\n",
    "            ad_date = list.find(\"div\", class_=\"list-view-date\").text.replace(\"\\n\",\"\")\n",
    "            room_number = list.find(\"span\", class_=\"celly houseRoomCount\").text.replace(\"\\n\",\"\")\n",
    "            age= list.find(\"span\", class_=\"celly buildingAge\").text.replace(\"\\n\",\"\")\n",
    "            condition = list.find(\"div\", class_=\"left\").text.replace(\"\\n\",\"\")\n",
    "\n",
    "            info = [title, location, price, metersquare, room_number, age, ad_date, condition]\n",
    "            thewriter.writerow(info)\n",
    "        return\n",
    "\n",
    "#Number of pages that is wanted to scrape and writing the data into csv file\n",
    "for x in range(1,61):\n",
    "    getRent(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee9ca93-c739-4353-a220-d3e743ec5732",
   "metadata": {},
   "source": [
    "### Sale Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386f8819-8c4c-42f9-8b71-c92ce712c4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Same script for Sale data\n",
    "\n",
    "with open(\"sale.csv\", \"w\", encoding=\"utf8\", newline=\"\") as f:\n",
    "    thewriter= csv.writer(f)\n",
    "    header = [\"Title\", \"Location\", \"Price\", \"MeterSquare\", \"Number of Rooms\", \"Age\", \"Ad Date\", \"Condition\"]\n",
    "    thewriter.writerow(header)\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.3 Safari/605.1.15\"}\n",
    "\n",
    "def getRent(page):\n",
    "    url = f\"https://www.hepsiemlak.com/izmir-satilik/daire?p37=120406&page={page}\"\n",
    "    page = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    lists = soup.find_all(\"div\", class_=\"listing-item\")\n",
    "\n",
    "\n",
    "\n",
    "    with open(\"sale.csv\", \"a\", encoding=\"utf8\", newline=\"\") as f:\n",
    "\n",
    "        thewriter= csv.writer(f)\n",
    "\n",
    "\n",
    "        for list in lists:\n",
    "            title = list.find(\"div\", class_=\"list-view-header\").text.replace(\"\\n\",\"\")\n",
    "            location = list.find(\"div\", class_=\"list-view-location\").text.replace(\"\\n\",\"\")\n",
    "            price = list.find(\"div\", class_=\"list-view-price\").text.replace(\"\\n\",\"\")\n",
    "            metersquare = list.find(\"span\", class_=\"celly squareMeter list-view-size\").text.replace(\"\\n\",\"\")\n",
    "            ad_date = list.find(\"div\", class_=\"list-view-date\").text.replace(\"\\n\",\"\")\n",
    "            room_number = list.find(\"span\", class_=\"celly houseRoomCount\").text.replace(\"\\n\",\"\")\n",
    "            age= list.find(\"span\", class_=\"celly buildingAge\").text.replace(\"\\n\",\"\")\n",
    "            condition = list.find(\"div\", class_=\"left\").text.replace(\"\\n\",\"\")\n",
    "\n",
    "            info = [title, location, price, metersquare, room_number, age, ad_date, condition]\n",
    "            thewriter.writerow(info)\n",
    "        return\n",
    "\n",
    "for x in range(1,258):\n",
    "    getRent(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e4ba00-5999-4328-a31c-0c9fd52bf0f1",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a87ff2-9245-4c76-8124-03464f6522a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data merging\n",
    "df_1 = pd.read_csv(\"rent.csv\")\n",
    "df_2 = pd.read_csv(\"sale.csv\")\n",
    "df = pd.concat([df_1, df_2], ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b0acdb-c1ca-42f3-a25b-4d5b8cc8bb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at our data frame more precisely\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2b5ceb-e842-4dec-9d09-928ee077c770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate ads\n",
    "df = df.drop_duplicates()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42239644-1639-4bd5-9f32-3e9978d2dada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to split 2 special columns to clean them\n",
    "df[[\"Location\",\"1\"]]=df[\"Location\"].str.split(\",\", expand=True)\n",
    "df[[\"Condition\",\"2\"]]=df[\"Condition\"].str.split(\" \",n = 1, expand=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc1f476-69e8-44e3-bf45-c6f48df0cc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping unnecessary columns\n",
    "df = df.drop([\"1\",\"2\"], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f231e913-f5b7-44fa-889a-ae83842973e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I will delete some words from each row in a column and translate some of Turkish words to English\n",
    "df[\"Price\"] = df[\"Price\"].str.replace(\"TL\",\"\", regex=True)\n",
    "df[\"Price\"] = df[\"Price\"].str.replace(\".\",\"\", regex=True)\n",
    "df[\"MeterSquare\"] = df[\"MeterSquare\"].str.replace(\"m2\",\"\", regex=True)\n",
    "df[\"Age\"] = df[\"Age\"].str.replace(\"Yaşında\",\"\", regex=True)\n",
    "df[\"Age\"] = df[\"Age\"].str.replace(\"Sıfır Bina\",\"0\", regex=True)\n",
    "df[\"Number of Rooms\"] = df[\"Number of Rooms\"].str.replace(\"Stüdyo\",\"1 + 0\", regex=True)\n",
    "df[\"Ad Date\"] = df[\"Ad Date\"].str.replace(\"Ocak\",\"01\", regex=True)\n",
    "df[\"Ad Date\"] = df[\"Ad Date\"].str.replace(\"Şubat\",\"02\", regex=True)\n",
    "df[\"Ad Date\"] = df[\"Ad Date\"].str.replace(\"Mart\",\"03\", regex=True)\n",
    "df[\"Condition\"] = df[\"Condition\"].str.replace(\"Satılık\",\"Sale\", regex=True)\n",
    "df[\"Condition\"] = df[\"Condition\"].str.replace(\"Kiralık\",\"Rent\", regex=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc955bb-e35b-4bea-ae0f-70378f5fad41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need to change style of Ad date column so first I will split column into 3 then concat them\n",
    "df[[\"Gün\",\"Ay\", \"Yıl\"]]= df[\"Ad Date\"].str.split(\" \", n= 2, expand=True)\n",
    "df[\"Ad Date\"] = df[\"Yıl\"] + \"-\" + df[\"Ay\"] + \"-\" + df[\"Gün\"]\n",
    "df = df.drop([\"Gün\",\"Ay\", \"Yıl\"], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885f9849-3dad-4582-8a0d-58881c885132",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b706eea-4e82-476e-9628-61b85ff6ebbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format types must be corrected \n",
    "df = df.astype({\"Price\": \"int32\"})\n",
    "df = df.astype({\"MeterSquare\": \"float64\"})\n",
    "df = df.astype({\"MeterSquare\": \"int32\"})\n",
    "df = df.astype({\"Ad Date\": \"datetime64\"})\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9933c652-2ac3-455f-907f-4ca02112c7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The outliers and wrong entries must be get rid off\n",
    "df[df[\"Condition\"]==\"Rent\"].sort_values(by = [\"Price\"]).tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04a3a1e-a658-45a3-b2b3-123dd102a3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checked the rent ads and there were couple ads for 3 months special to summer (84 rows deleted)\n",
    "df = df.drop(df[(df[\"Condition\"] == \"Rent\") & (df[\"Price\"] > 21000)].index)\n",
    "df[df[\"Condition\"]==\"Rent\"].sort_values(by = [\"Price\"]).tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daea02a9-03d7-43c0-a2b8-eab2430194f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sale outliers and wrong entries\n",
    "df[df[\"Condition\"]==\"Sale\"].sort_values(by = [\"Price\"]).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d13577-f9d5-4dfc-94a8-9d838d9b32fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 rows deleted\n",
    "df = df.drop(df[(df[\"Condition\"] == \"Sale\") & (df[\"Price\"] < 80000)].index)\n",
    "df[df[\"Condition\"]==\"Sale\"].sort_values(by = [\"Price\"]).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074e4323-e749-4d69-ba21-4032aadbb355",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"Condition\"]==\"Sale\"].sort_values(by = [\"Price\"]).tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686301b3-54e7-4c0c-abaf-6d0ce78ea5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 rows deleted\n",
    "df = df.drop(df[(df[\"Condition\"] == \"Sale\") & (df[\"Price\"] >16400000)].index)\n",
    "df[df[\"Condition\"]==\"Sale\"].sort_values(by = [\"Price\"]).tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bed542-3ea5-4c68-b5c5-9f259d167ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting blank title ads and triming the data\n",
    "df.dropna(subset=['Title'], inplace=True)\n",
    "df[\"Location\"]=df[\"Location\"].str.strip()\n",
    "df[\"Title\"]=df[\"Title\"].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430919d3-a46c-4de8-b290-819c165a56d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping the Data\n",
    "df.groupby([\"Location\", \"Condition\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe87702-2818-4a82-83ce-a2f77fe58799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The districts without enough data won't be counted in the analysis of data \n",
    "noinfoloc= [\"Aliağa\", \"Bayındır\", \"Beydağ\" ,\"Kiraz\", \"Selçuk\" , \"Tire\" ,\"Kınık\"]\n",
    "df = df.drop(df[df[\"Location\"].isin(noinfoloc)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c584d8d-520e-446d-b235-7705e3143091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving as CSV data\n",
    "df.to_csv(\"clean_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdadb34e-c848-4faa-86d4-c4fbd88a9f84",
   "metadata": {},
   "source": [
    "## Analysis of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112967cd-cbc3-48b1-a5bd-a0902018cd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean prices and mt^2 for specific locations and conditions\n",
    "a= df.groupby([\"Location\", \"Condition\"]).mean()\n",
    "a = a.astype({\"Price\": \"int32\"})\n",
    "a = a.astype({\"MeterSquare\": \"int32\"})\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c846037-afb4-438c-8187-5829c6662890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the return of investment after 5 years in percentage\n",
    "a2 = a.unstack()\n",
    "a2[\"Percentage\"] = a2.Price.Rent/a2.Price.Sale*60\n",
    "a5 = a2[[\"Percentage\"]] #for creating plot\n",
    "a2[\"Percentage\"] = pd.Series([\"{0:.2f}%\".format(val * 100) for val in a2['Percentage']], index = a2.index)\n",
    "a2=a2[[\"Price\", \"Percentage\"]] \n",
    "a2.sort_values(\"Percentage\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc986d31-ef1b-45ef-9c53-2faac1b6283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change in rents for last 3 months\n",
    "ax= df.groupby([ df[\"Location\"], df[\"Condition\"], df['Ad Date'].dt.strftime('%B')])[\"Price\"].mean()\n",
    "ax = ax.astype({\"Price\": \"int32\"})\n",
    "ax = ax.unstack()\n",
    "ax[np.in1d(ax.index.get_level_values(1), ['Rent'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c34a57e-d0dd-41a9-bca3-0757844ac0bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Ploting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121de5f8-5d45-48df-9d5f-3f4deade9e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a5 is created from a2 to create plot\n",
    "a5[\"index1\"] = a5.index\n",
    "a5[\"Percentage\"] = a5[\"Percentage\"]*100\n",
    "a5 = a5.sort_values(\"Percentage\", ascending=False)\n",
    "a5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4cb7c3-851b-4c9b-b6f8-1dc984e2d9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line Chart\n",
    "\n",
    "b = a5[\"index1\"]\n",
    "c = a5[\"Percentage\"]\n",
    "\n",
    "# create the graph\n",
    "plt.plot(c)\n",
    "\n",
    "# label the x and y axes\n",
    "plt.xlabel('Location', weight='bold', size='large')\n",
    "plt.ylabel('Percentage', weight='bold', size='large')\n",
    "\n",
    "# format the x and y ticks\n",
    "plt.xticks(range(len(c)), b, rotation= 65, horizontalalignment='right', size='large')\n",
    "plt.yticks(size='large')\n",
    "\n",
    "# give it a title\n",
    "plt.title(\"Return of Investment After 5 Years\", weight='bold')\n",
    "\n",
    "# displays the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0feec06-4888-4a5d-a30a-8ea61ce2c2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar char\n",
    "my_plot = a5.plot(kind='bar', legend=None)\n",
    "\n",
    "# labels the x and y axes\n",
    "my_plot.set_xlabel('Location')\n",
    "my_plot.set_ylabel('Percentage')\n",
    "\n",
    "# sets the labels along the x-axis as the names of each liquor\n",
    "my_plot.set_xticklabels(b, rotation=65, horizontalalignment='right')\n",
    "\n",
    "# displays the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb2c35e-633c-4cfb-831a-490f977954fd",
   "metadata": {},
   "source": [
    "## Insights \n",
    "**Dikili** has the highest percentage in return and also shows really high increase in the rents in last 3 months. So, It might be good idea to invest in **Dikili**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d42940-17ab-4f7b-a3a9-fcb5b69a62ef",
   "metadata": {},
   "source": [
    "## Uploading Table into BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292e6dab-9138-49dc-86e0-3dd55f9253d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "def create_dataset(deneme, US):\n",
    "    client = bigquery.Client()\n",
    "    reference = client.dataset('Real_Estate_Investment')\n",
    "    try:\n",
    "        client.get_dataset(reference)\n",
    "    except NotFound:\n",
    "        dataset = bigquery.Dataset(reference)\n",
    "        dataset.location = \"US\"\n",
    "\n",
    "        dataset = client.create_dataset(dataset)\n",
    "\n",
    "create_dataset('Real_Estate_Investment','US')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b6e820-8945-4e3c-be8d-38b38be1ddb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading to dataset\n",
    "PROJECT_ID = \"local-incline-341518\"\n",
    "client = bigquery.Client()\n",
    "client.create_table(f\"{PROJECT_ID}.Real_Estate_Investment.clean_data\")\n",
    "filename = \"clean_data.csv\"\n",
    "dataset_id = \"Real_Estate_Investment\"\n",
    "table_id = \"clean_data\"\n",
    "\n",
    "dataset_ref = client.dataset(dataset_id)\n",
    "table_ref = dataset_ref.table(table_id)\n",
    "job_config = bigquery.LoadJobConfig()\n",
    "job_config.source_format = bigquery.SourceFormat.CSV\n",
    "job_config.autodetect = True\n",
    "\n",
    "with open(filename, \"rb\") as source_file:\n",
    "    job = client.load_table_from_file(source_file, table_ref, job_config=job_config)\n",
    "job.result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
